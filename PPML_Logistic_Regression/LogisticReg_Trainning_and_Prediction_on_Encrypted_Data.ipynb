{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3723af54",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8305592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b86ffd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x, y, ratio=0.3):\n",
    "    torch.random.manual_seed(0)\n",
    "    random.seed(0)\n",
    "    idxs = list(range(len(x)))\n",
    "    random.shuffle(idxs)\n",
    "    split_idx = int(len(x)*ratio)\n",
    "    test_idxs, train_idxs = idxs[:split_idx], idxs[split_idx:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438fe9f",
   "metadata": {},
   "source": [
    "Data is at: https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression/code?datasetId=222487&sortBy=voteCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60ac1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_heart_disease_data():\n",
    "    data = pd.read_csv(\"../data/framingham.csv\")\n",
    "    # Drop target columns\n",
    "    X = data.drop(['TenYearCHD'], axis=1, inplace=False)\n",
    "    Y = data['TenYearCHD']\n",
    "    X = X.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    # Standardize data\n",
    "    X = (X - X.mean()) / X.std()\n",
    "    X = torch.tensor(X.values).float()\n",
    "    Y = torch.tensor(Y.values).float().unsqueeze(1)\n",
    "    \n",
    "    return split_train_test(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d87922",
   "metadata": {},
   "source": [
    "# Train a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2be53416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([2967, 15])\n",
      "y_train has shape: torch.Size([2967, 1])\n",
      "x_test has shape: torch.Size([1271, 15])\n",
      "y_test has shape: torch.Size([1271, 1])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare_heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e0b2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4da852b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae0d1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 100: 0.3662443161010742\n",
      "Loss at epoch 200: 0.3658924102783203\n",
      "Loss at epoch 300: 0.36558932065963745\n",
      "Loss at epoch 400: 0.3653271496295929\n",
      "Loss at epoch 500: 0.36509963870048523\n",
      "Loss at epoch 600: 0.3649013936519623\n",
      "Loss at epoch 700: 0.36472824215888977\n",
      "Loss at epoch 800: 0.36457642912864685\n",
      "Loss at epoch 900: 0.36444300413131714\n",
      "Loss at epoch 1000: 0.3643253743648529\n"
     ]
    }
   ],
   "source": [
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 1000\n",
    "torch.random.manual_seed(0)\n",
    "random.seed(0)\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if e % 100 == 0:\n",
    "            print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fd651dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.8363493084907532\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d5547",
   "metadata": {},
   "source": [
    "# Integrate CKKS into Logistic Regression Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7f8a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        # TenSEAL processes lists and not torch tensors,\n",
    "        # so we take out the parameters from the PyTorch model\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        # We don't need to perform sigmoid as this model\n",
    "        # will only be used for evaluation, and the label\n",
    "        # can be deduced without applying sigmoid\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "\n",
    "eelr = EncryptedLR(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7138de3",
   "metadata": {},
   "source": [
    "## Generate CKKS key pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "585c5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d1b27",
   "metadata": {},
   "source": [
    "## Encrypt the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a0b1e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 2 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82c1fd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bdb53f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test_set of 1271 entries in 5 seconds\n",
      "Accuracy: 1054/1271 = 0.8292682926829268\n",
      "Difference between plain and encrypted accuracies: 0.007081031799316406\n"
     ]
    }
   ],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "    \n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bc301",
   "metadata": {},
   "source": [
    "# Integrate CKKS into Logistic Regression Model for Prediction\n",
    "...to be continued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
